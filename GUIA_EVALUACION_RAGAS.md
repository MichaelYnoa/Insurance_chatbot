# üìä Gu√≠a de Ejecuci√≥n - Evaluaci√≥n RAGAS del Insurance Chatbot

Esta gu√≠a explica paso a paso c√≥mo ejecutar el notebook de evaluaci√≥n RAGAS para medir la calidad del sistema RAG del Insurance Chatbot.

---

## üéØ Objetivo

Evaluar la calidad del sistema RAG (Retrieval-Augmented Generation) del chatbot de seguros utilizando el framework RAGAS, midiendo m√©tricas clave como:
- **Faithfulness** (Fidelidad)
- **Answer Relevancy** (Relevancia de Respuesta)
- **Context Recall** (Recuperaci√≥n de Contexto)
- **Context Precision** (Precisi√≥n de Contexto)

---

## ‚öôÔ∏è Requisitos Previos

### 1. Base de Datos ChromaDB
Aseg√∫rate de que existe la base de datos ChromaDB con los documentos de seguros:

```bash
# Verificar que existe el directorio
ls backend/chroma_db/
```

Si no existe, debes construirla primero:

```bash
cd backend/src
python chroma_db_builder.py
```

### 2. API Key de Google Gemini
Necesitas una API key v√°lida de Google Gemini configurada en tu archivo `.env`:

```bash
# Crear archivo .env en la ra√≠z del proyecto si no existe
cp .env.example .env

# Editar .env y agregar tu API key
GOOGLE_API_KEY=tu_api_key_aqui
```

Para obtener una API key gratuita:
1. Ve a [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Inicia sesi√≥n con tu cuenta de Google
3. Crea una nueva API key
4. C√≥piala en tu archivo `.env`

---

## üì¶ Instalaci√≥n de Dependencias

### Paso 1: Instalar dependencias del backend

```bash
cd backend
pip install -r requirements.txt
```

### Paso 2: Instalar RAGAS y dependencias adicionales

```bash
pip install ragas datasets matplotlib
```

**Nota:** RAGAS requiere las siguientes bibliotecas que se instalar√°n autom√°ticamente:
- `langchain`
- `openai` (para embeddings)
- `datasets` (Hugging Face)

### Paso 3: Verificar instalaci√≥n

```bash
python -c "import ragas; print('RAGAS version:', ragas.__version__)"
```

---

## üöÄ Ejecuci√≥n del Notebook

### Opci√≥n 1: Jupyter Notebook (Recomendado)

1. **Instalar Jupyter** (si no lo tienes):
   ```bash
   pip install jupyter notebook
   ```

2. **Iniciar Jupyter Notebook**:
   ```bash
   # Desde la ra√≠z del proyecto
   jupyter notebook
   ```

3. **Abrir el notebook**:
   - En el navegador que se abre, navega a `ragas_evaluation.ipynb`
   - Haz clic para abrirlo

4. **Ejecutar las celdas**:
   - Ejecuta cada celda secuencialmente presionando `Shift + Enter`
   - O ejecuta todas las celdas: `Cell > Run All`

### Opci√≥n 2: JupyterLab

1. **Instalar JupyterLab**:
   ```bash
   pip install jupyterlab
   ```

2. **Iniciar JupyterLab**:
   ```bash
   jupyter lab
   ```

3. **Abrir y ejecutar** el notebook `ragas_evaluation.ipynb`

### Opci√≥n 3: Google Colab

1. Sube el notebook a Google Colab
2. Sube tambi√©n los archivos necesarios del proyecto
3. Modifica las rutas seg√∫n sea necesario
4. Ejecuta las celdas

### Opci√≥n 4: VS Code

1. Abre VS Code en la ra√≠z del proyecto
2. Instala la extensi√≥n "Jupyter" de Microsoft
3. Abre `ragas_evaluation.ipynb`
4. Selecciona el kernel de Python apropiado
5. Ejecuta las celdas

---

## üìã Proceso de Evaluaci√≥n

El notebook ejecuta los siguientes pasos autom√°ticamente:

### 1. Importaciones y Configuraci√≥n (Celdas 1-3)
- Importa bibliotecas necesarias
- Configura rutas y variables de entorno
- Importa m√≥dulos del chatbot

### 2. Inicializaci√≥n del Chatbot (Celdas 4-5)
- Verifica la existencia de ChromaDB
- Inicializa el chatbot con la configuraci√≥n apropiada
- Conecta a la API de Google Gemini

### 3. Dataset Sint√©tico (Celda 6)
- Carga 30 preguntas predefinidas sobre seguros m√©dicos
- Cada pregunta incluye su respuesta esperada (ground truth)

### 4. Generaci√≥n de Respuestas (Celdas 7-9)
- El chatbot procesa cada pregunta
- Recupera contextos relevantes de ChromaDB
- Genera respuestas usando Google Gemini
- **‚è±Ô∏è Tiempo estimado**: 5-10 minutos

### 5. Evaluaci√≥n RAGAS (Celdas 10-12)
- Convierte el dataset al formato de RAGAS
- Ejecuta las 4 m√©tricas de evaluaci√≥n
- **‚è±Ô∏è Tiempo estimado**: 10-15 minutos

### 6. Visualizaci√≥n de Resultados (Celdas 13-16)
- Muestra estad√≠sticas resumidas
- Genera gr√°ficos de barras
- Analiza mejores y peores respuestas
- Guarda resultados en archivos CSV

---

## üìä Resultados Generados

Al finalizar la ejecuci√≥n, se generan los siguientes archivos:

1. **`ragas_evaluation_results.csv`**
   - Resultados detallados por cada pregunta
   - Todas las m√©tricas calculadas
   - Preguntas, respuestas y contextos

2. **`ragas_metrics_summary.csv`**
   - Resumen estad√≠stico de las m√©tricas
   - Promedios, desviaci√≥n est√°ndar, m√≠nimos y m√°ximos

3. **Gr√°ficos en el notebook**
   - Gr√°fico de barras con las 4 m√©tricas principales
   - Visualizaciones de distribuci√≥n de puntuaciones

---

## üîç Interpretaci√≥n de Resultados

### Escala de Puntuaci√≥n
Todas las m√©tricas se miden en una escala de **0 a 1**, donde:
- **0.8 - 1.0**: Excelente
- **0.6 - 0.8**: Bueno
- **0.4 - 0.6**: Aceptable
- **0.0 - 0.4**: Necesita mejora

### Qu√© Significa Cada M√©trica

#### 1. Faithfulness (Fidelidad) - 0 a 1
- **Qu√© mide**: Si la respuesta est√° basada en el contexto recuperado
- **Valor alto (>0.8)**: La respuesta es fiel al contexto, sin "alucinaciones"
- **Valor bajo (<0.5)**: El modelo est√° inventando informaci√≥n

#### 2. Answer Relevancy (Relevancia) - 0 a 1
- **Qu√© mide**: Si la respuesta es relevante para la pregunta
- **Valor alto (>0.8)**: Respuesta directa y pertinente
- **Valor bajo (<0.5)**: Respuesta desviada o incompleta

#### 3. Context Recall (Recuperaci√≥n) - 0 a 1
- **Qu√© mide**: Si el contexto recuperado contiene la informaci√≥n necesaria
- **Valor alto (>0.8)**: Buena recuperaci√≥n de documentos relevantes
- **Valor bajo (<0.5)**: El sistema de b√∫squeda no encuentra informaci√≥n relevante

#### 4. Context Precision (Precisi√≥n) - 0 a 1
- **Qu√© mide**: Si los documentos m√°s relevantes est√°n primero en el ranking
- **Valor alto (>0.8)**: Buen ordenamiento de resultados
- **Valor bajo (<0.5)**: Documentos irrelevantes rankeados primero

---

## üõ†Ô∏è Soluci√≥n de Problemas

### Error: "No module named 'ragas'"
```bash
pip install ragas datasets
```

### Error: "ChromaDB not found"
```bash
cd backend/src
python chroma_db_builder.py
```

### Error: "GOOGLE_API_KEY not found"
1. Verifica que existe el archivo `.env` en la ra√≠z del proyecto
2. Aseg√∫rate de que contiene: `GOOGLE_API_KEY=tu_key_aqui`
3. Reinicia el kernel del notebook

### Error: "Rate limit exceeded"
- Est√°s haciendo demasiadas llamadas a la API de Gemini
- Espera unos minutos e intenta de nuevo
- Considera reducir el n√∫mero de preguntas en el dataset

### Ejecuci√≥n muy lenta
- Normal: RAGAS realiza m√∫ltiples llamadas a LLMs para cada m√©trica
- Tiempo t√≠pico: 15-20 minutos para 30 preguntas
- Para pruebas r√°pidas: reduce `evaluation_questions` a 5-10 preguntas

### Error de memoria
- Cierra otros programas
- Reduce el n√∫mero de preguntas en el dataset
- Usa un entorno con m√°s RAM disponible

---

## üéì Mejores Pr√°cticas

### 1. Primera Ejecuci√≥n
- Empieza con 5-10 preguntas para verificar que todo funciona
- Luego ejecuta el dataset completo de 30 preguntas

### 2. Iteraci√≥n y Mejora
1. Ejecuta la evaluaci√≥n con la configuraci√≥n actual
2. Analiza los resultados
3. Ajusta par√°metros del chatbot:
   - `max_context_docs`: n√∫mero de documentos recuperados
   - Tama√±o de chunks en ChromaDB
   - System prompt del chatbot
4. Re-ejecuta la evaluaci√≥n
5. Compara resultados

### 3. Personalizaci√≥n
- Puedes agregar tus propias preguntas al dataset
- Aseg√∫rate de incluir el `ground_truth` (respuesta correcta)
- Mant√©n preguntas relevantes al dominio de seguros m√©dicos

---

## üìà Acciones Seg√∫n Resultados

### Si Faithfulness es bajo (<0.6)
- **Problema**: El modelo est√° alucinando informaci√≥n
- **Soluci√≥n**: 
  - Ajustar el system prompt para enfatizar "responder solo con el contexto"
  - Reducir la temperatura del modelo
  - Revisar la calidad de los chunks en ChromaDB

### Si Answer Relevancy es bajo (<0.6)
- **Problema**: Respuestas no relevantes a las preguntas
- **Soluci√≥n**:
  - Mejorar el system prompt
  - Verificar que las preguntas est√©n bien formuladas
  - Ajustar el modelo de generaci√≥n

### Si Context Recall es bajo (<0.6)
- **Problema**: No se recupera informaci√≥n relevante
- **Soluci√≥n**:
  - Aumentar `max_context_docs`
  - Mejorar el chunking de documentos
  - Verificar calidad de embeddings
  - Considerar re-indexar ChromaDB

### Si Context Precision es bajo (<0.6)
- **Problema**: Documentos irrelevantes rankeados primero
- **Soluci√≥n**:
  - Ajustar el algoritmo de scoring
  - Mejorar metadata de documentos
  - Considerar hybrid search (keyword + semantic)

---

## üìû Soporte

Si encuentras problemas:
1. Verifica que todas las dependencias est√°n instaladas
2. Revisa los logs de error en el notebook
3. Consulta la documentaci√≥n de RAGAS: https://docs.ragas.io/
4. Revisa el c√≥digo fuente del chatbot en `backend/src/`

---

## ‚úÖ Checklist de Ejecuci√≥n

Antes de ejecutar el notebook, verifica:

- [ ] ChromaDB construido (`backend/chroma_db/` existe)
- [ ] GOOGLE_API_KEY configurado en `.env`
- [ ] Dependencias instaladas (`ragas`, `datasets`, `matplotlib`)
- [ ] Jupyter o JupyterLab instalado
- [ ] Conexi√≥n a internet (para llamadas a API de Gemini)
- [ ] Al menos 15-20 minutos disponibles para ejecuci√≥n completa

---

## üéØ Resultados Esperados

Al finalizar exitosamente, deber√≠as tener:

1. ‚úÖ Tabla resumen con las 4 m√©tricas RAGAS
2. ‚úÖ Gr√°fico de barras visualizando las m√©tricas
3. ‚úÖ An√°lisis de top 5 mejores y peores respuestas
4. ‚úÖ Archivos CSV con resultados detallados
5. ‚úÖ Interpretaci√≥n clara de la calidad del sistema RAG

---

## üìö Recursos Adicionales

- **Documentaci√≥n RAGAS**: https://docs.ragas.io/
- **Paper RAGAS**: https://arxiv.org/abs/2309.15217
- **Google Gemini Docs**: https://ai.google.dev/docs
- **ChromaDB Docs**: https://docs.trychroma.com/

---

**Nota Final**: Esta evaluaci√≥n es completamente **no intrusiva**. No modifica ning√∫n archivo del proyecto original, solo lee la configuraci√≥n existente y genera nuevos archivos de resultados.
